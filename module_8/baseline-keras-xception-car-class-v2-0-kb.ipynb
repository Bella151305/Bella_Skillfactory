{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"> Это пример решения задачи с использованием Keras. Вы можете использовать этот кернер для дальнейших исследований и экспериментов.\n# Классификация изображений\n\n### Основная идея этого решения: взять предобученую на ImageNet сеть Xception и дообучить под нашу задачу. \nПо ходу решения мы будем давать вам рекомендации, которые помогут улучшить качество модели. \n\n\nУдачи и Поехали!","metadata":{}},{"cell_type":"code","source":"!nvidia-smi","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -q efficientnet","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pickle\nimport zipfile\nimport csv\nimport sys\nimport os\n\n\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import LearningRateScheduler, ModelCheckpoint, EarlyStopping\nfrom tensorflow.keras.callbacks import Callback\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.applications.xception import Xception\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.backend import clear_session\nimport tensorflow.keras as keras\nimport efficientnet.tfkeras as efn\n\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\n\nimport PIL\nfrom PIL import ImageOps, ImageFilter\n#увеличим дефолтный размер графиков\nfrom pylab import rcParams\nrcParams['figure.figsize'] = 10, 5\n#графики в svg выглядят более четкими\n%config InlineBackend.figure_format = 'svg' \n%matplotlib inline\n\nprint(os.listdir(\"../input\"))\nprint('Python       :', sys.version.split('\\n')[0])\nprint('Numpy        :', np.__version__)\nprint('Tensorflow   :', tf.__version__)\nprint('Keras        :', tf.keras.__version__)","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_kg_hide-input":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Работаем с Tensorflow v2**","metadata":{}},{"cell_type":"code","source":"!pip freeze > requirements.txt","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Основные настройки","metadata":{}},{"cell_type":"code","source":"# В setup выносим основные настройки: так удобнее их перебирать в дальнейшем.\n\n# EPOCHS               = 5  # эпох на обучение\n# EPOCHS               = 20  # смена модели, аугментация, early stopping\n# BATCH_SIZE           = 64 # уменьшаем batch если сеть большая, иначе не влезет в память на GPU\nBATCH_SIZE           = 8 # пришлось снизить из-за увеличения размера картинки/сети\n# LR                   = 1e-4 # Accuracy: 92.10%\nLR                   = 1e-3 # для fine tuning\nVAL_SPLIT            = 0.15 # сколько данных выделяем на тест = 15%\n\nCLASS_NUM            = 10  # количество классов в нашей задаче\nIMG_SIZE             = 224 # какого размера подаем изображения в сеть\n# Accuracy: 92.10%\n# IMG_SIZE             = 360 вернулм меньший для fine tuning\n# Accuracy: 94.68% очень долго считается, высокий уровень переобучения\n# Accuracy: 96.96% новая модель\nIMG_CHANNELS         = 3   # у RGB 3 канала\ninput_shape          = (IMG_SIZE, IMG_SIZE, IMG_CHANNELS)\n\nDATA_PATH = '../input/'\nPATH = \"../working/car/\" # рабочая директория","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Устаналиваем конкретное значение random seed для воспроизводимости\n# os.makedirs(PATH,exist_ok=False)\n\nRANDOM_SEED = 42\nnp.random.seed(RANDOM_SEED)  \nPYTHONHASHSEED = 0","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EDA / Анализ данных","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv(DATA_PATH+\"train.csv\")\nsample_submission = pd.read_csv(DATA_PATH+\"sample-submission.csv\")\ntrain_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.Category.value_counts()\n# распределение классов достаточно равномерное - это хорошо","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Распаковываем картинки')\n# Will unzip the files so that you can see them..\nfor data_zip in ['train.zip', 'test.zip']:\n    with zipfile.ZipFile(\"../input/\"+data_zip,\"r\") as z:\n        z.extractall(PATH)\n        \nprint(os.listdir(PATH))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Пример картинок (random sample)')\nplt.figure(figsize=(12,8))\n\nrandom_image = train_df.sample(n=9)\nrandom_image_paths = random_image['Id'].values\nrandom_image_cat = random_image['Category'].values\n\nfor index, path in enumerate(random_image_paths):\n    im = PIL.Image.open(PATH+f'train/{random_image_cat[index]}/{path}')\n    plt.subplot(3,3, index+1)\n    plt.imshow(im)\n    plt.title('Class: '+str(random_image_cat[index])+' size: '+str(im.size))\n    plt.axis('off')\nplt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Посмотрим на примеры картинок и их размеры чтоб понимать как их лучше обработать и сжимать.","metadata":{}},{"cell_type":"code","source":"image = PIL.Image.open(PATH+'/train/0/100380.jpg')\nimgplot = plt.imshow(image)\nplt.show()\nimage.size","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Уже догадываетесь, что означают классы?","metadata":{}},{"cell_type":"markdown","source":"# Подготовка данных","metadata":{}},{"cell_type":"markdown","source":"### Аугментация данных","metadata":{}},{"cell_type":"code","source":"# Вы помните, что аугментация данных важна, когда мы работаем с небольшим датасетом. Это как раз наш случай.\n# Чтобы лучше понять работу параметров, попробуйте их изменить. К какому результату это приведет?\n# Официальная документация: https://keras.io/preprocessing/image/\n\n# train_datagen = ImageDataGenerator(\n#     rescale=1. / 255,\n#     rotation_range = 5,\n#     width_shift_range=0.1,\n#     height_shift_range=0.1,\n#     validation_split=VAL_SPLIT, # set validation split\n#     horizontal_flip=False)\n# Accuracy: 92.10%\n\n# train_datagen = ImageDataGenerator(\n#     rescale=1. / 255,\n#     rotation_range = 5,\n#     width_shift_range=0.1,\n#     height_shift_range=0.1,\n#     channel_shift_range=0.1,\n#     zoom_range=[0.75,1.25],\n#     brightness_range=[0.5, 1.5],\n#     fill_mode='nearest', # One of {\"constant\", \"nearest\", \"reflect\" or \"wrap\"}\n#     validation_split=VAL_SPLIT, # set validation split\n#     horizontal_flip=True)\n# Accuracy: 91.24%\n\ntrain_datagen = ImageDataGenerator(\n    rescale=1. / 255,\n    rotation_range = 5,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    # channel_shift_range=0.1,\n    # zoom_range=[0.75,1.25],\n    brightness_range=[0.5, 1.5],\n    fill_mode='constant', # One of {\"constant\", \"nearest\", \"reflect\" or \"wrap\"}\n    validation_split=VAL_SPLIT, # set validation split\n    horizontal_flip=True)\n# Accuracy: 92.61% - попробовать больше эпох\n\ntest_datagen = ImageDataGenerator(rescale=1. / 255)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Рекомендация Подключите более продвинутые библиотеки аугментации изображений (например: albumentations или imgaug, для них есть специальные \"обертки\" под Keras, например: \n\nhttps://github.com/mjkvaak/ImageDataAugmentor)","metadata":{}},{"cell_type":"markdown","source":"### Генерация данных","metadata":{}},{"cell_type":"code","source":"# Завернем наши данные в генератор:\n\ntrain_generator = train_datagen.flow_from_directory(\n    PATH+'train/',      # директория где расположены папки с картинками \n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    shuffle=True, seed=RANDOM_SEED,\n    subset='training') # set as training data\n\ntest_generator = train_datagen.flow_from_directory(\n    PATH+'train/',\n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    shuffle=True, seed=RANDOM_SEED,\n    subset='validation') # set as validation data\n\ntest_sub_generator = test_datagen.flow_from_dataframe( \n    dataframe=sample_submission,\n    directory=PATH+'test_upload/',\n    x_col=\"Id\",\n    y_col=None,\n    shuffle=False,\n    class_mode=None,\n    seed=RANDOM_SEED,\n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,)\n\n# Обратите внимание, что для сабмита мы используем другой источник test_datagen.flow_from_dataframe. Как вы думаете, почему?","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from skimage import io\n\ndef imshow(image_RGB):\n  io.imshow(image_RGB)\n  io.show()\n\nrandom_image_paths = random_image['Id'].values\nrandom_image_cat = random_image['Category'].values\n    \nx,y = train_generator.next()\nprint('Пример картинок из train_generator')\nplt.figure(figsize=(12,8))\n\nfor i in range(0,6):\n    image = x[i]\n    plt.subplot(3,3, i+1)\n    plt.imshow(image)\n    plt.title('Class: '+str(y[i]))\n    # plt.title('size: '+str(image.size))\n    plt.axis('off')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Построение модели","metadata":{}},{"cell_type":"markdown","source":"### Загружаем предобученную сеть Xception:","metadata":{}},{"cell_type":"code","source":"clear_session()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# base_model = Xception(weights='imagenet', include_top=False, input_shape = input_shape)\n# Accuracy: 92.10%\n# base_model = tf.keras.applications.ResNet50V2(weights='imagenet', include_top=False, input_shape=input_shape)\n# Accuracy: 89.91% может, добавить больше эпох?\nbase_model = efn.EfficientNetB6(weights='imagenet', include_top=False, input_shape=input_shape)\n# Accuracy: 94.42% нет переобучения - увеличить количество эпох\n# Accuracy: 96.96% после увеличения размера изображения и количества эпох - началось переобучение","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_model.summary()\n# Рекомендация: Попробуйте и другие архитектуры сетей","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# first: train only the top layers (which were randomly initialized)\nbase_model.trainable = False","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Устанавливаем новую \"голову\" (head)\n\nx = base_model.output\nx = GlobalAveragePooling2D()(x)\n# let's add a fully-connected layer\n# x = Dense(256, activation='relu')(x) # для fine tuning\n# Accuracy: 92.10%\n# x = Dense(256, activation='relu')(x)\n# Accuracy: %\nx = BatchNormalization()(x)\n# Accuracy: 92.36%\nx = Dropout(0.25)(x)\n# and a logistic layer -- let's say we have 10 classes\npredictions = Dense(CLASS_NUM, activation='softmax')(x)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Обучение модели","metadata":{}},{"cell_type":"code","source":"# Check the trainable status of the individual layers\n# for layer in model.layers:\n#     print(layer, layer.trainable)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# this is the model we will train\nmodel = Model(inputs=base_model.input, outputs=predictions)\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.Adam(lr=LR), metrics=[\"accuracy\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()\n# Рекомендация: Попробуйте добавить Batch Normalization","metadata":{"_kg_hide-input":false,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(model.layers))\nprint(len(model.trainable_variables))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Добавим ModelCheckpoint чтоб сохранять прогресс обучения модели и можно было потом подгрузить и дообучить модель.","metadata":{}},{"cell_type":"code","source":"checkpoint = ModelCheckpoint('best_model.hdf5' , monitor = ['val_accuracy'] , verbose = 1  , mode = 'max')\nearlystopping = EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)\n\ncallbacks_list = [checkpoint, earlystopping]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"1. Рекомендация 1. Добавьте другие функции из https://keras.io/callbacks/\n2. Рекомендация 2. Используйте разные техники управления Learning Rate\n\nhttps://towardsdatascience.com/finding-good-learning-rate-and-the-one-cycle-policy-7159fe1db5d6 (eng)\n\nhttp://teleported.in/posts/cyclic-learning-rate/ (eng)","metadata":{}},{"cell_type":"markdown","source":"Обучаем:","metadata":{}},{"cell_type":"code","source":"# history = model.fit_generator(\n#         train_generator,\n#         steps_per_epoch = len(train_generator),\n#         validation_data = test_generator, \n#         validation_steps = len(test_generator),\n#         epochs = EPOCHS,\n#         callbacks = callbacks_list)\n\n# Рекомендация: попробуйте применить transfer learning с fine-tuning","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### fine-tuning","metadata":{}},{"cell_type":"code","source":"# Обучаем\nhistory = model.fit_generator(\n                    train_generator,\n                    steps_per_epoch = len(train_generator),\n                    validation_data = test_generator, \n                    validation_steps = len(test_generator),\n                    epochs = 5,\n                    callbacks = callbacks_list\n                    )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# сохраним итоговую сеть и подгрузим лучшую итерацию в обучении (best_model)\nmodel.save('../working/model_last.hdf5')\nmodel.load_weights('best_model.hdf5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scores = model.evaluate_generator(test_generator, steps=len(test_generator), verbose=1)\nprint(\"Accuracy: %.2f%%\" % (scores[1]*100))","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n \nepochs = range(len(acc))\n \nplt.plot(epochs, acc, 'b', label='Training acc')\nplt.plot(epochs, val_acc, 'r', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\n \nplt.figure()\n \nplt.plot(epochs, loss, 'b', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\n \nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Мы видим, что точность на валидации уменьшилась. Похоже на переобучение, но не торопитесь останавливать обучение - может быть это просто случайность. \n\nРекомендация. Попробуйте увеличить количество эпох, может быть точность модели на валидации снова начнет расти? Вы можете использовать callback keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True): он останавливает обучение, когда точность на валидации не растет в течение patience эпох. Чем больше patience, тем надежнее вывод о том, что модель достигла своего максимума качества. Если вы используете EarlyStoping, то параметр epochs в методе .fit() - это максимальное количество эпох, после которого обучение точно остановится.","metadata":{}},{"cell_type":"code","source":"# Let's take a look to see how many layers are in the base model\nprint(\"Number of layers in the base model: \", len(base_model.layers))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_model.trainable = True\n\n# Fine-tune from this layer onwards\nfine_tune_at = len(base_model.layers)//2\n\n# Freeze all the layers before the `fine_tune_at` layer\nfor layer in base_model.layers[:fine_tune_at]:\n  layer.trainable =  False\n\nlen(base_model.trainable_variables)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"LR=0.0001\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.Adam(lr=LR), metrics=[\"accuracy\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scores = model.evaluate_generator(test_generator, verbose=1)\nprint(\"Accuracy: %.2f%%\" % (scores[1]*100))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Обучаем\nhistory = model.fit_generator(\n        train_generator,\n        steps_per_epoch = len(train_generator),\n        validation_data = test_generator, \n        validation_steps = len(test_generator),\n        epochs = 10,\n        callbacks = callbacks_list)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('../working/model_step2.hdf5')\nmodel.load_weights('best_model.hdf5')\n\nscores = model.evaluate_generator(test_generator, verbose=1)\nprint(\"Accuracy: %.2f%%\" % (scores[1]*100))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n \nepochs = range(len(acc))\n \nplt.plot(epochs, acc, 'b', label='Training acc')\nplt.plot(epochs, val_acc, 'r', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\n \nplt.figure()\n \nplt.plot(epochs, loss, 'b', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\n \nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_model.trainable = True\n\nLR=0.00001\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.Adam(lr=LR), metrics=[\"accuracy\"])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Обучаем\nhistory = model.fit_generator(\n        train_generator,\n        steps_per_epoch = len(train_generator),\n        validation_data = test_generator, \n        validation_steps = len(test_generator),\n        epochs = 10,\n        callbacks = callbacks_list\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('../working/model_step3.hdf5')\nmodel.load_weights('best_model.hdf5')\n\nscores = model.evaluate_generator(test_generator, verbose=1)\nprint(\"Accuracy: %.2f%%\" % (scores[1]*100))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n \nepochs = range(len(acc))\n \nplt.plot(epochs, acc, 'b', label='Training acc')\nplt.plot(epochs, val_acc, 'r', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\n \nplt.figure()\n \nplt.plot(epochs, loss, 'b', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\n \nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"EPOCHS               = 10\nBATCH_SIZE           = 4 # уменьшаем batch если сеть большая, иначе не влезет в память на GPU\nLR                   = 1e-5\n\nIMG_SIZE             = 360\nIMG_CHANNELS         = 3\ninput_shape          = (IMG_SIZE, IMG_SIZE, IMG_CHANNELS)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_datagen = ImageDataGenerator(\n    rescale=1. / 255,\n    rotation_range = 5,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    # channel_shift_range=0.1,\n    # zoom_range=[0.75,1.25],\n    brightness_range=[0.5, 1.5],\n    fill_mode='constant', # One of {\"constant\", \"nearest\", \"reflect\" or \"wrap\"}\n    validation_split=VAL_SPLIT, # set validation split\n    horizontal_flip=True)\n\ntest_datagen = ImageDataGenerator(rescale=1. / 255)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Завернем наши данные в генератор:\n\ntrain_generator = train_datagen.flow_from_directory(\n    PATH+'train/',      # директория где расположены папки с картинками \n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    shuffle=True, seed=RANDOM_SEED,\n    subset='training') # set as training data\n\ntest_generator = train_datagen.flow_from_directory(\n    PATH+'train/',\n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    shuffle=True, seed=RANDOM_SEED,\n    subset='validation') # set as validation data\n\ntest_sub_generator = test_datagen.flow_from_dataframe( \n    dataframe=sample_submission,\n    directory=PATH+'test_upload/',\n    x_col=\"Id\",\n    y_col=None,\n    shuffle=False,\n    class_mode=None,\n    seed=RANDOM_SEED,\n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_model = efn.EfficientNetB6(weights='imagenet', include_top=False, input_shape=input_shape)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.Adam(lr=LR), metrics=[\"accuracy\"])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.load_weights('best_model.hdf5')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Обучаем\nhistory = model.fit_generator(\n        train_generator,\n        steps_per_epoch = len(train_generator),\n        validation_data = test_generator, \n        validation_steps = len(test_generator),\n        epochs = EPOCHS,\n        callbacks = callbacks_list\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('../working/model_step4.hdf5')\nmodel.load_weights('best_model.hdf5')\n\nscores = model.evaluate_generator(test_generator, verbose=1)\nprint(\"Accuracy: %.2f%%\" % (scores[1]*100))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n \nepochs = range(len(acc))\n \nplt.plot(epochs, acc, 'b', label='Training acc')\nplt.plot(epochs, val_acc, 'r', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\n \nplt.figure()\n \nplt.plot(epochs, loss, 'b', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\n \nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Предсказание на тестовых данных","metadata":{}},{"cell_type":"code","source":"test_sub_generator.samples","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_sub_generator.reset()\npredictions = model.predict_generator(test_sub_generator, steps=len(test_sub_generator), verbose=1) \npredictions = np.argmax(predictions, axis=-1) #multiple categories\nlabel_map = (train_generator.class_indices)\nlabel_map = dict((v,k) for k,v in label_map.items()) #flip k,v\npredictions = [label_map[k] for k in predictions]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filenames_with_dir=test_sub_generator.filenames\nsubmission = pd.DataFrame({'Id':filenames_with_dir, 'Category':predictions}, columns=['Id', 'Category'])\nsubmission['Id'] = submission['Id'].replace('test_upload/','')\nsubmission.to_csv('submission.csv', index=False)\nprint('Save submit')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Рекомендация: попробуйте добавить Test Time Augmentation (TTA)\n\nhttps://towardsdatascience.com/test-time-augmentation-tta-and-how-to-perform-it-with-keras-4ac19b67fb4d","metadata":{}},{"cell_type":"code","source":"submission.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Clean PATH\nimport shutil\nshutil.rmtree(PATH)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Интересно, к какому классу модель отнесет вот эти автомобили?","metadata":{}},{"cell_type":"markdown","source":"# Что можно сделать, чтобы улучшить результат:","metadata":{}},{"cell_type":"markdown","source":"* Примените transfer learning с fine-tuning\n* Настройте LR, optimizer, loss\n* Подберите другие переменные (размер картинки, батч и т.д.)\n* Попробуйте и другие архитектуры сетей (а не только Xception) или их ансамбли. Примеры SOTA на ImageNet  \n* \n* Добавьте Batch Normalization и поэкспериментируйте с архитектурой “головы”\n* Примените другие функции callback Keras https://keras.io/callbacks/ \n* Добавьте TTA (Test Time Augmentation)\n* Дополнительно*: Используйте разные техники управления Learning Rate (https://towardsdatascience.com/finding-good-learning-rate-and-the-one-cycle-policy-7159fe1db5d6 (eng) http://teleported.in/posts/cyclic-learning-rate/ (eng))\n* Дополнительно*: Добавьте более продвинутые библиотеки аугментации изображений (например, Albumentations )\n\n### Удачи в соревновании!","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}